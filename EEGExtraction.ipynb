{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8_pci0fM1xu",
        "outputId": "d7f27f00-a477-4b05-a61e-247fe72fdbc4"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "from scipy import signal\n",
        "from scipy.fft import fftshift\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW79sou-OFlo",
        "outputId": "cc95e3f8-3fc1-4edd-b46b-a6b0fb9c21b4"
      },
      "outputs": [],
      "source": [
        "def fileToLabeled(path= \"./edfs/S005/S005E01.edf\"):\n",
        "  data = mne.io.read_raw_edf(path,verbose='CRITICAL')\n",
        "  filtered=data.load_data(verbose='CRITICAL').filter(0.5, 43, verbose='CRITICAL')\n",
        "  raw_data=filtered.get_data() \n",
        "  lst=[]\n",
        "  for i in range(len(data.ch_names)):\n",
        "    if i==8: continue\n",
        "    start_range=0\n",
        "    sec_range=180\n",
        "    channel=i\n",
        "    f, t, specs = signal.spectrogram(raw_data[channel][256*start_range:256*sec_range],256, nperseg=256,noverlap=0)\n",
        "    theta_new=[]\n",
        "    for a in range(sec_range-start_range):\n",
        "      theta_new.append((specs[4][a]+specs[5][a]+specs[6][a]+specs[7][a]))\n",
        "\n",
        "    beta_new=[]\n",
        "    for a in range(sec_range-start_range):\n",
        "      beta_new.append((specs[13][a]+specs[14][a]+specs[15][a]+specs[16][a]+specs[17][a]+specs[18][a]+specs[19][a]+specs[20][a]\n",
        "              +specs[21][a]+specs[22][a]+specs[23][a]+specs[24][a]+specs[25][a]))\n",
        "\n",
        "    ratio=[theta_new[i]/beta_new[i] for i in range(sec_range-start_range)]\n",
        "    lst.append(ratio)\n",
        "  lst.append([(0 if (i<60 or i>120) else 1) for i in t])\n",
        "  res=np.array(lst).T\n",
        "  return res\n",
        "\n",
        "def folderToLabeled(path=\"./edfs/S001/\"):\n",
        "  fnames = os.listdir(path)\n",
        "  lst=[]\n",
        "  for i in fnames:\n",
        "    #print(f\"!!!!!!!!!!!! Processing {i}...\")\n",
        "    rat=fileToLabeled(path+i)\n",
        "    for j in rat:\n",
        "      lst.append(j)\n",
        "  return np.array(lst)\n",
        "\n",
        "def projectTo(path=\"./edfs/\"):\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:06<00:00,  4.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S001 -> train:0.6736111111111112, test:0.6875\n",
            "S002 -> train:0.6614583333333334, test:0.6875\n",
            "S003 -> train:0.6805555555555556, test:0.6597222222222222\n",
            "S004 -> train:0.6875, test:0.6458333333333334\n",
            "S005 -> train:0.6979166666666666, test:0.6597222222222222\n",
            "S006 -> train:0.7065972222222222, test:0.7152777777777778\n",
            "S007 -> train:0.671875, test:0.6527777777777778\n",
            "S008 -> train:0.7083333333333334, test:0.7222222222222222\n",
            "S009 -> train:0.6875, test:0.6388888888888888\n",
            "S010 -> train:0.6510416666666666, test:0.6944444444444444\n",
            "S011 -> train:0.6440972222222222, test:0.7361111111111112\n",
            "S012 -> train:0.6614583333333334, test:0.6875\n",
            "S013 -> train:0.7013888888888888, test:0.5625\n",
            "S014 -> train:0.6753472222222222, test:0.6666666666666666\n",
            "S015 -> train:0.6545138888888888, test:0.7291666666666666\n",
            "S016 -> train:0.6788194444444444, test:0.6944444444444444\n",
            "S017 -> train:0.6701388888888888, test:0.6875\n",
            "S018 -> train:0.6736111111111112, test:0.7222222222222222\n",
            "S019 -> train:0.6736111111111112, test:0.6666666666666666\n",
            "S020 -> train:0.671875, test:0.6805555555555556\n",
            "S021 -> train:0.6927083333333334, test:0.6458333333333334\n",
            "S022 -> train:0.6701388888888888, test:0.6597222222222222\n",
            "S023 -> train:0.6736111111111112, test:0.7083333333333334\n",
            "S024 -> train:0.6666666666666666, test:0.6666666666666666\n",
            "S025 -> train:0.6736111111111112, test:0.7013888888888888\n",
            "S026 -> train:0.6545138888888888, test:0.7083333333333334\n",
            "S027 -> train:0.6875, test:0.6180555555555556\n",
            "S028 -> train:0.6892361111111112, test:0.625\n",
            "S029 -> train:0.6666666666666666, test:0.7083333333333334\n",
            "S030 -> train:0.6892361111111112, test:0.5972222222222222\n",
            "avg:0.6745370370370369, std:0.04027585101305951\n",
            "bestacc:0.7361111111111112, besta:S011, ind:29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from statistics import stdev\n",
        "from tqdm import tqdm\n",
        "def getData(data :np.ndarray, test=0.2, shuffled=True, trim=0.5):\n",
        "    copied=data.copy()\n",
        "    if shuffled:\n",
        "        np.random.shuffle(copied)\n",
        "    cnt=len(copied)\n",
        "    testr=math.floor(cnt*test)\n",
        "    trainr=math.floor(cnt*(1-test))\n",
        "    return (copied[:trainr], copied[trainr:trainr+testr])\n",
        "def classify(data):\n",
        "    new=data.T\n",
        "    input=new[:13]\n",
        "    label=new[13]\n",
        "    return (input.T, label)\n",
        "\n",
        "def work():\n",
        "    res=[]\n",
        "    ldaarr=[]\n",
        "    for i in tqdm([f\"S{i:03}\" for i in range(1,31)]):\n",
        "        data=folderToLabeled(f\"./edfs/{i}/\")\n",
        "        (train, test)=getData(data)\n",
        "        x, y=classify(train)\n",
        "        x_test, y_test=classify(test)\n",
        "        lda=LinearDiscriminantAnalysis()\n",
        "        scaled = x#StandardScaler().fit_transform(x.T)\n",
        "        scaled_test = x_test#StandardScaler().fit_transform(x_test.T)\n",
        "        lda.fit(scaled, y)\n",
        "        y_predict=lda.predict(scaled_test)\n",
        "        y_train_pred=lda.predict(scaled)\n",
        "        res.append((i, metrics.accuracy_score(y, y_train_pred), metrics.accuracy_score(y_test, y_predict)))\n",
        "        ldaarr.append(lda)\n",
        "    sum=0\n",
        "    stdarr=[]\n",
        "    bestind=0\n",
        "    bestacc=0\n",
        "    besta=\"\"\n",
        "    for ind, i in enumerate(res):\n",
        "        print(f\"{i[0]} -> train:{i[1]}, test:{i[2]}\")\n",
        "        sum+=i[2]\n",
        "        stdarr.append(i[2])\n",
        "        if i[2]>bestacc:\n",
        "            bestacc=i[2]\n",
        "            bestind=ind\n",
        "            besta=i[0]\n",
        "    print(f\"avg:{sum/len(res)}, std:{stdev(stdarr)}\")\n",
        "    print(f\"bestacc:{bestacc}, besta:{besta}, ind:{ind}\")\n",
        "    return (ldaarr, bestind, besta)\n",
        "(ldas, ind, bestname)=work()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on ./edfs/S011/S011E03.edf\n",
            "csv accuracy:0.6555555555555556\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from ntpath import basename\n",
        "def ExportToCsv(model :LinearDiscriminantAnalysis, path=\"./edfs/S012/S012E03.edf\"):\n",
        "    def softmax(x):\n",
        "        f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "        return f_x\n",
        "    print(f\"Working on {path}\")\n",
        "    ratio=fileToLabeled(path)\n",
        "    (input, label)=classify(ratio)\n",
        "    predicted=model.predict(input)\n",
        "    score=metrics.accuracy_score(label, predicted)\n",
        "    print(f\"csv accuracy:{score}\")\n",
        "    #csv\n",
        "    work=np.array(input)\n",
        "    for i, d in enumerate(input):\n",
        "        work[i]=softmax(d)*(0.5 if predicted[i] is 0 else 1)\n",
        "    df = pd.DataFrame(work)\n",
        "    root, extension = os.path.splitext(path)\n",
        "    df.to_csv(basename(root)+\".csv\", index=False)\n",
        "ExportToCsv(ldas[ind], f\"./edfs/{bestname}/{bestname}E03.edf\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "edf_alphabeta.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit ('3.7.9')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "bd221f5f171a5cf1110bccf59e7ce38fbb52895b355b0a20126ec69308631072"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
